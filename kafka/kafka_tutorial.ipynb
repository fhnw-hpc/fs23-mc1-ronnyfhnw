{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "def connect_kafka_producer(servers):\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=servers, api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')\n",
    "        value_bytes = bytes(value, encoding='utf-8')\n",
    "        producer_instance.send(topic_name, key=key_bytes, value=value_bytes)\n",
    "        producer_instance.flush()\n",
    "        print('Message published successfully.')\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message')\n",
    "        print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def produce_xy(producer, topic_name):\n",
    "    while True:\n",
    "        name = f'Mark {random.randint(0,22)}'\n",
    "        message = json.dumps({\"name\": name})\n",
    "        print(name)\n",
    "        publish_message(producer, topic_name, str(uuid.uuid4()), message)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consume_xy(consumer, topic_name):\n",
    "\n",
    "    for msg in consumer:\n",
    "        print(msg.key.decode(\"utf-8\"), msg.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server1 = 'broker1:9093'\n",
    "topic1 = \"names\"\n",
    "\n",
    "producer = connect_kafka_producer(server1)\n",
    "\n",
    "consumer = KafkaConsumer(topic1, \n",
    "                         auto_offset_reset='earliest',\n",
    "                         bootstrap_servers=[server1], \n",
    "                         api_version=(0, 10), \n",
    "                         value_deserializer = json.loads,\n",
    "                         consumer_timeout_ms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark 15\n",
      "Message published successfully.\n",
      "Mark 2\n",
      "Message published successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mproduce_xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mproduce_xy\u001b[0;34m(producer, topic_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m      9\u001b[0m publish_message(producer, topic_name, \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()), message)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "produce_xy(producer, topic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e7b73a19-b0c0-44af-8255-995661757591 {'name': 'Mark 15'}\n",
      "1505ba3f-d1fa-4d41-8610-46d99404fa54 {'name': 'Mark 2'}\n"
     ]
    }
   ],
   "source": [
    "consume_xy(consumer, topic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka_functions import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using <function <lambda> at 0x7fb252e97640> as value serializer.\n",
      "Using <function <lambda> at 0x7fb252ea7760> as key serializer.\n",
      "Message published successfully.\n"
     ]
    }
   ],
   "source": [
    "publish_message(twitter_producer, topic_name=twitter_topic, key=str(uuid.uuid4()), value=\"hallelujah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumed 5 messages from Kafka Cluster\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ConsumerRecord(topic='twitter', partition=0, offset=0, timestamp=1678352827588, timestamp_type=0, key='92fd878c-54c9-48a3-940e-e9139c03f44f', value='hallelujah', headers=[], checksum=None, serialized_key_size=36, serialized_value_size=25, serialized_header_size=-1),\n",
       " ConsumerRecord(topic='twitter', partition=0, offset=1, timestamp=1678352998375, timestamp_type=0, key='bcfda319-3677-4ac9-a69a-3670950426d1', value='hallelujah', headers=[], checksum=None, serialized_key_size=36, serialized_value_size=25, serialized_header_size=-1),\n",
       " ConsumerRecord(topic='twitter', partition=0, offset=2, timestamp=1678353082099, timestamp_type=0, key='a8a4e2dc-f129-4fa3-9118-b8a220bb0d1b', value='hallelujah', headers=[], checksum=None, serialized_key_size=36, serialized_value_size=25, serialized_header_size=-1),\n",
       " ConsumerRecord(topic='twitter', partition=0, offset=3, timestamp=1678353289387, timestamp_type=0, key='fd455466-c4f1-4a9c-9fb9-fd0dc1eff75c', value='hallelujah', headers=[], checksum=None, serialized_key_size=36, serialized_value_size=25, serialized_header_size=-1),\n",
       " ConsumerRecord(topic='twitter', partition=0, offset=4, timestamp=1678353499281, timestamp_type=0, key='c4b5ac61-d8b6-4844-8695-c350cdabd9bd', value='hallelujah', headers=[], checksum=None, serialized_key_size=36, serialized_value_size=25, serialized_header_size=-1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consume_messages(twitter_consumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using <function <lambda> at 0x7fb252ea7eb0> as value serializer.\n",
      "Using <function <lambda> at 0x7fb252f18040> as key serializer.\n",
      "Message published successfully.\n"
     ]
    }
   ],
   "source": [
    "publish_message(binance_producer, topic_name=binance_topic, key=str(uuid.uuid4()), value=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumed 2 messages from Kafka Cluster\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ConsumerRecord(topic='binance-ws', partition=0, offset=0, timestamp=1678353503437, timestamp_type=0, key=b'a41ac0fa-f728-47fb-a274-a651d14d767f', value='test', headers=[], checksum=2094713400, serialized_key_size=36, serialized_value_size=6, serialized_header_size=-1),\n",
       " ConsumerRecord(topic='binance-ws', partition=0, offset=1, timestamp=1678353504630, timestamp_type=0, key=b'fb75f945-93c6-4822-b896-8bad87052208', value={'key': 'value'}, headers=[], checksum=3716824245, serialized_key_size=36, serialized_value_size=16, serialized_header_size=-1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consume_messages(binance_consumer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c29d78f68b3adfe34490f0a9c8485ca5e60d8ebbc4e20be2f75bad5d0b699416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
